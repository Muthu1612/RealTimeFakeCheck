{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eea98893-4260-4038-895f-a81eb053266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, img, vid, aud):\n",
    "\n",
    "        self.img_emb = img[\"embeddings\"]\n",
    "        self.vid_emb = vid[\"embeddings\"]\n",
    "        self.aud_emb = aud[\"embeddings\"]\n",
    "        self.labels = torch.logical_and(img[\"labels\"] == 1, aud[\"labels\"] == 1).long()\n",
    "\n",
    "        assert len(self.img_emb) == len(self.vid_emb)\n",
    "        # print(len(self.img_emb), len(self.vid_emb), len(self.aud_emb))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.img_emb[idx],       # (6529)\n",
    "            self.vid_emb[idx],       # (6529)\n",
    "            self.aud_emb[idx],       # (53868)\n",
    "            self.labels[idx]         # scalar\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9edbbdc-63d4-4a5c-8901-12c6dd5a632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"embeddings/image_embeddings.pt\"\n",
    "vid_path = \"embeddings/video_embeddings.pt\"\n",
    "aud_path = \"embeddings/audio_embeddings.pt\"\n",
    "img = torch.load(img_path)\n",
    "vid = torch.load(vid_path)\n",
    "aud = torch.load(aud_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a780fc61-b81e-41cf-9fb5-3402d9a2554e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([53868])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aud[\"labels\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b97955-aa4e-4bd1-8875-d91e28d10df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(aud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5fe0002-3551-49f7-bc25-39be55a141f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embeddings': tensor([[-0.3066, -0.2047, -0.0683,  ..., -0.1312, -0.1106,  0.1742],\n",
       "         [-0.1104, -0.1327,  0.0353,  ..., -0.0845,  0.0210, -0.0060],\n",
       "         [-0.0369, -0.3680,  0.0231,  ..., -0.0512, -0.0616, -0.0716],\n",
       "         ...,\n",
       "         [-0.3582, -0.3175, -0.1303,  ..., -0.0630,  0.0294,  0.1945],\n",
       "         [-0.2436, -0.3054, -0.0577,  ...,  0.0968, -0.0503,  0.2423],\n",
       "         [-0.1108, -0.4214,  0.0558,  ..., -0.0789, -0.0576, -0.0923]],\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " 'labels': tensor([0, 1, 1,  ..., 0, 0, 1])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aud_projection = nn.Linear(768, 512)\n",
    "aud_embed_512 = aud_projection(aud[\"embeddings\"])\n",
    "dim_reduced_aud = {}\n",
    "dim_reduced_aud[\"embeddings\"] = aud_embed_512\n",
    "dim_reduced_aud[\"labels\"] = aud[\"labels\"]\n",
    "dim_reduced_aud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f193c919-69fe-45ea-a55d-8f9cafd82370",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = dim_reduced_aud[\"embeddings\"]  \n",
    "lbl = dim_reduced_aud[\"labels\"] \n",
    "\n",
    "B, D = emb.shape\n",
    "k = B // 6529\n",
    "B_new = 6529 * k\n",
    "\n",
    "perm = torch.randperm(B)\n",
    "emb_shuffled = emb[perm]\n",
    "lbl_shuffled = lbl[perm]\n",
    "\n",
    "emb_trim = emb_shuffled[:B_new]\n",
    "lbl_trim = lbl_shuffled[:B_new]\n",
    "\n",
    "emb_reshaped = emb_trim.view(6529, k, 512)      # [6529, k, 512]\n",
    "emb_pooled = emb_reshaped.mean(dim=1)           # [6529, 512]\n",
    "\n",
    "lbl_reshaped = lbl_trim.view(6529, k)           # [6529, k]\n",
    "lbl_final = lbl_reshaped.mode(dim=1).values     # majority vote, shape [6529]\n",
    "\n",
    "# 5. Pack results\n",
    "aud_pooled = {\n",
    "    \"embeddings\": emb_pooled,\n",
    "    \"labels\": lbl_final\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f702ccf4-f61f-41ad-b10c-d4cf8b9e1597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embeddings': tensor([[-0.2038, -0.2742, -0.0172,  ..., -0.0917,  0.0087,  0.0459],\n",
       "         [-0.1821, -0.3958, -0.0130,  ..., -0.1146,  0.0150,  0.0079],\n",
       "         [-0.1709, -0.2794,  0.0339,  ..., -0.0696,  0.1286, -0.0282],\n",
       "         ...,\n",
       "         [-0.1735, -0.3745, -0.0219,  ..., -0.0481, -0.0325,  0.0464],\n",
       "         [-0.2033, -0.3057,  0.0142,  ..., -0.1043,  0.0705,  0.0232],\n",
       "         [-0.2173, -0.2382,  0.0565,  ..., -0.0454, -0.0009,  0.0303]],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " 'labels': tensor([0, 0, 0,  ..., 1, 0, 0])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aud_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c45c3b1-7242-4b61-a457-21262d89e2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6529, 512]), torch.Size([6529, 512]), torch.Size([6529, 512]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = EmbeddingDataset(img, vid, aud_pooled)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "dataset.img_emb.shape, dataset.vid_emb.shape, dataset.aud_emb.shape\n",
    "# for img_emb, vid_emb, aud_emb in loader:\n",
    "#     print(\"img embeddings: \", img_emb.shape)\n",
    "#     print(\"vid embeddings: \", vid_emb.shape)\n",
    "#     print(\"aud embeddings: \", aud_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44c36021-7530-4025-9ac2-4b546a376584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FusionClassifier(nn.Module):\n",
    "    def __init__(self, embed_dim=512):\n",
    "        super().__init__()\n",
    "\n",
    "        fusion_dim = embed_dim * 3   # img_emb + vid_emb = 1024\n",
    "\n",
    "        self.fc1 = nn.Linear(fusion_dim, 512)\n",
    "        self.ln1 = nn.LayerNorm(512)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.ln2 = nn.LayerNorm(256)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc_out = nn.Linear(256, 2)  # For CrossEntropy (real/fake)\n",
    "\n",
    "    def forward(self, img_emb, vid_emb, aud_emb):\n",
    "        x = torch.cat([img_emb, vid_emb, aud_emb], dim=1)\n",
    "        x = F.relu(self.ln1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.ln2(self.fc2(x)))\n",
    "        return self.fc_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "727a7961-3dec-447a-8d3d-2499b2a93bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Loss=114.3643 | Acc=0.7134\n",
      "Epoch 2/50 | Loss=98.5730 | Acc=0.7666\n",
      "Epoch 3/50 | Loss=94.8755 | Acc=0.7839\n",
      "Epoch 4/50 | Loss=93.2012 | Acc=0.7879\n",
      "Epoch 5/50 | Loss=91.2878 | Acc=0.7906\n",
      "Epoch 6/50 | Loss=89.2786 | Acc=0.7896\n",
      "Epoch 7/50 | Loss=88.1678 | Acc=0.8007\n",
      "Epoch 8/50 | Loss=87.8355 | Acc=0.7920\n",
      "Epoch 9/50 | Loss=86.0160 | Acc=0.8009\n",
      "Epoch 10/50 | Loss=84.7077 | Acc=0.8047\n",
      "Epoch 11/50 | Loss=86.4613 | Acc=0.8013\n",
      "Epoch 12/50 | Loss=83.0796 | Acc=0.8099\n",
      "Epoch 13/50 | Loss=84.4831 | Acc=0.8046\n",
      "Epoch 14/50 | Loss=82.3835 | Acc=0.8102\n",
      "Epoch 15/50 | Loss=83.6175 | Acc=0.8110\n",
      "Epoch 16/50 | Loss=82.4906 | Acc=0.8153\n",
      "Epoch 17/50 | Loss=81.9328 | Acc=0.8127\n",
      "Epoch 18/50 | Loss=82.5600 | Acc=0.8099\n",
      "Epoch 19/50 | Loss=80.1833 | Acc=0.8157\n",
      "Epoch 20/50 | Loss=79.3212 | Acc=0.8223\n",
      "Epoch 21/50 | Loss=78.3036 | Acc=0.8229\n",
      "Epoch 22/50 | Loss=78.7574 | Acc=0.8219\n",
      "Epoch 23/50 | Loss=76.7085 | Acc=0.8268\n",
      "Epoch 24/50 | Loss=76.9387 | Acc=0.8260\n",
      "Epoch 25/50 | Loss=82.4264 | Acc=0.8134\n",
      "Epoch 26/50 | Loss=77.7211 | Acc=0.8222\n",
      "Epoch 27/50 | Loss=74.6950 | Acc=0.8282\n",
      "Epoch 28/50 | Loss=75.2031 | Acc=0.8309\n",
      "Epoch 29/50 | Loss=72.7909 | Acc=0.8323\n",
      "Epoch 30/50 | Loss=72.6313 | Acc=0.8403\n",
      "Epoch 31/50 | Loss=71.1484 | Acc=0.8416\n",
      "Epoch 32/50 | Loss=71.0188 | Acc=0.8427\n",
      "Epoch 33/50 | Loss=70.1229 | Acc=0.8461\n",
      "Epoch 34/50 | Loss=69.5309 | Acc=0.8476\n",
      "Epoch 35/50 | Loss=69.6222 | Acc=0.8461\n",
      "Epoch 36/50 | Loss=66.3803 | Acc=0.8565\n",
      "Epoch 37/50 | Loss=67.0567 | Acc=0.8551\n",
      "Epoch 38/50 | Loss=65.2521 | Acc=0.8602\n",
      "Epoch 39/50 | Loss=66.2308 | Acc=0.8534\n",
      "Epoch 40/50 | Loss=67.7997 | Acc=0.8487\n",
      "Epoch 41/50 | Loss=66.1841 | Acc=0.8534\n",
      "Epoch 42/50 | Loss=64.3859 | Acc=0.8603\n",
      "Epoch 43/50 | Loss=62.4177 | Acc=0.8645\n",
      "Epoch 44/50 | Loss=64.5244 | Acc=0.8597\n",
      "Epoch 45/50 | Loss=64.1345 | Acc=0.8588\n",
      "Epoch 46/50 | Loss=63.7940 | Acc=0.8551\n",
      "Epoch 47/50 | Loss=60.8827 | Acc=0.8635\n",
      "Epoch 48/50 | Loss=59.6900 | Acc=0.8692\n",
      "Epoch 49/50 | Loss=59.9892 | Acc=0.8704\n",
      "Epoch 50/50 | Loss=57.6344 | Acc=0.8743\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = FusionClassifier(embed_dim=512).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for img_emb, vid_emb, aud_emb, labels in loader:\n",
    "        \n",
    "        img_emb = img_emb.detach().to(device)\n",
    "        vid_emb = vid_emb.detach().to(device)\n",
    "        aud_emb = aud_emb.detach().to(device)\n",
    "        \n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(img_emb, vid_emb, aud_emb)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss={total_loss:.4f} | Acc={acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbb24151-5c02-41ba-8fc2-28c90d0a01f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"ml_model/fusion_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c57915-c9dd-473e-b1ef-4e4fb951dd02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
